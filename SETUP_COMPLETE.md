# Banking RAG System - Complete Setup Summary

## ‚úÖ System Configuration Status

### Core Components
- ‚úÖ Java 17 compatibility issues fixed
- ‚úÖ Spring Boot 3.2.4 configured
- ‚úÖ PostgreSQL + pgvector ready
- ‚úÖ Maven build successful

### RAG Architecture Fixes Applied
- ‚úÖ Chat history excluded from vector search (prevents pollution)
- ‚úÖ Enhanced local embeddings with location weighting
- ‚úÖ Similarity threshold increased from 0.01 ‚Üí 0.3
- ‚úÖ OpenAI LLM provider configured
- ‚úÖ Results panel UI added with detailed analytics

### OpenAI Configuration
- ‚úÖ LLM provider set to: `openai`
- ‚úÖ Model configured: `gpt-4o-mini`
- ‚úÖ API key configured via environment variable
- ‚úÖ Environment file templates created (`.env.example`)
- ‚úÖ Startup script created (`start-with-openai.sh`)
- ‚úÖ Security: `.gitignore` configured to protect API keys

## üìÅ Files Created/Modified

### Configuration Files
```
‚úì src/main/resources/application.yml - OpenAI enabled, threshold increased
‚úì .env.example - API key template
‚úì .gitignore - Protects sensitive data
```

### Scripts
```
‚úì start-with-openai.sh - Auto-loads .env and starts app
```

### Documentation
```
‚úì OPENAI_SETUP.md - Comprehensive OpenAI configuration guide
‚úì QUICKSTART.md - Step-by-step setup instructions
‚úì README.md - Updated with OpenAI section
```

### Code Fixes
```
‚úì VectorStoreRepository.java - Excludes chat history from search
‚úì EmbeddingService.java - Enhanced with location-aware weighting
‚úì SyntheticDataGenerator.java - Fixed lambda variable scope issue
‚úì index.html - Fixed API endpoint, added results panel
‚úì pom.xml - Fixed Java 17 compiler configuration
```

## üöÄ How to Start

### Prerequisites
1. **Docker Desktop** running (for PostgreSQL)
2. **OpenAI API Key** from https://platform.openai.com/api-keys

### Quick Start (3 Steps)

```bash
# Step 1: Create .env file with your API key
cd /Users/zenobiusselvadhason/work/project/Zeto/banking-rag
cp .env.example .env
nano .env  # Add your API key: OPENAI_API_KEY=sk-proj-xxx

# Step 2: Ensure PostgreSQL is running
docker-compose up -d

# Step 3: Start the application
./start-with-openai.sh
```

### What Happens on Startup

1. **Data Generation** (~3-5 minutes)
   - 100,000 customers created
   - ~250,000 accounts generated
   - ~6.8M transactions synthesized

2. **Vector Indexing** (~2-3 minutes)
   - 100,000 document embeddings created
   - Customer profiles, accounts, transactions indexed
   - Banking policies added to knowledge base

3. **Server Ready**
   - Web UI: http://localhost:8080
   - API: http://localhost:8080/api

## üß™ Testing the System

### Test 1: Verify OpenAI is Working

```bash
# Query the system
curl -X POST http://localhost:8080/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What is the overdraft protection policy?"}'
```

**Expected:** Natural language response from OpenAI, NOT "=== RAG Response (Mock LLM) ==="

### Test 2: Location-Based Query

```bash
curl -X POST http://localhost:8080/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Which customers are from New York?"}'
```

**Expected:** Actual customers with "New York" or "NY" in their location

### Test 3: Check System Status

```bash
curl http://localhost:8080/api/admin/status
```

**Expected:**
```json
{
  "status": "UP",
  "customers": 100000,
  "accounts": 249623,
  "transactions": 6871825,
  "embeddings": 100000
}
```

### Test 4: Web UI

Open browser to: http://localhost:8080

**Expected:**
- Status: "Connected" (green dot)
- Customer/Account/Transaction counts displayed
- Sample queries on left sidebar
- Results panel on right (after first query)

## üìä Expected Query Results

### Before Fixes (Incorrect)
```
Query: "Which customers are from New York?"

Result: Returns random customers from Texas, Washington, etc.
- Similarity scores: 0.04-0.06 (very low)
- Chat history appearing in results
- No location matching
```

### After Fixes (Correct)
```
Query: "Which customers are from New York?"

Result: Actual New York customers
- Similarity scores: 0.3-0.7 (good to excellent)
- No chat history pollution
- Location terms properly weighted
- Natural language answer from OpenAI
```

## üîß Configuration Options

### Switch Back to Mock LLM (No API Key Needed)

Edit `application.yml`:
```yaml
rag:
  llm:
    provider: mock  # Change from 'openai' to 'mock'
```

### Use Ollama Instead (Free Local LLM)

```bash
# Install and start Ollama
brew install ollama
ollama pull llama3
ollama serve
```

Edit `application.yml`:
```yaml
rag:
  llm:
    provider: ollama
```

### Adjust Result Quality

Edit `application.yml`:
```yaml
rag:
  retrieval:
    top-k: 10              # Number of documents to retrieve
    similarity-threshold: 0.3  # Minimum similarity (0-1)
```

Higher threshold = fewer but more relevant results

## üí∞ OpenAI Costs

### gpt-4o-mini (Default - Recommended)
- Input: $0.150 per 1M tokens
- Output: $0.600 per 1M tokens
- **Per query: ~$0.001**
- **1,000 queries: ~$1.00**

### gpt-4o (Higher Quality)
- Input: $5.00 per 1M tokens
- Output: $15.00 per 1M tokens
- **Per query: ~$0.02**
- **1,000 queries: ~$20.00**

## üîê Security Best Practices

‚úÖ **Never commit `.env` to version control** - It's in `.gitignore`  
‚úÖ **Use environment variables in production** - Never hardcode keys  
‚úÖ **Rotate API keys regularly** - Every 90 days recommended  
‚úÖ **Monitor usage** - https://platform.openai.com/usage  
‚úÖ **Set billing limits** - Protect against unexpected costs  
‚úÖ **Use separate keys for dev/prod** - Easier to track and revoke  

## üìö Additional Documentation

| File | Description |
|------|-------------|
| [QUICKSTART.md](QUICKSTART.md) | Step-by-step setup guide |
| [OPENAI_SETUP.md](OPENAI_SETUP.md) | Detailed OpenAI configuration |
| [README.md](README.md) | Full system documentation |

## üêõ Troubleshooting

### Application won't start
```bash
# Check if port 8080 is in use
lsof -i :8080

# Kill existing process
kill -9 <PID>
```

### OpenAI errors
```bash
# Verify API key is set
echo $OPENAI_API_KEY

# Test API key
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

### Still getting mock responses
```bash
# Verify configuration
grep "provider:" src/main/resources/application.yml

# Should show:
#   llm:
#     provider: openai
```

### Database connection errors
```bash
# Check PostgreSQL is running
docker ps | grep postgres

# Restart PostgreSQL
docker-compose down
docker-compose up -d
```

## üéØ Next Steps

1. **Set up your OpenAI API key** (see Quick Start above)
2. **Start the application** with `./start-with-openai.sh`
3. **Test queries** via Web UI or API
4. **Monitor costs** at https://platform.openai.com/usage
5. **Fine-tune** similarity threshold based on your needs
6. **(Optional)** Re-index with OpenAI embeddings for even better results

## üìà Performance Expectations

| Metric | Value |
|--------|-------|
| Query latency | 500ms - 2s (depends on OpenAI) |
| Embedding generation | Local: instant, OpenAI: ~100ms |
| Documents retrieved | 10 (configurable) |
| Similarity scores | 0.3 - 0.9 (with enhanced embeddings) |
| Concurrent queries | ~100/min (rate limited by OpenAI) |

## ‚ú® New Features

### Results Panel (Right Sidebar)
- Query overview with quality indicator
- Performance metrics (response time, avg similarity)
- Source breakdown by type
- Top similarity scores visualization
- System info (embedding/LLM providers)

### Enhanced Embeddings
- Location-aware weighting (cities, states)
- Multi-word location support ("New York", "Fort Worth")
- 2-3x weight boost for important terms

### Chat History Exclusion
- Previous conversations no longer pollute results
- Cleaner, more relevant document retrieval

---

**Your Banking RAG system is now configured and ready to use with OpenAI!** üéâ

Follow the Quick Start steps above to begin.

